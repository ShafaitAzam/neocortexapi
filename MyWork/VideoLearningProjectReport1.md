# Investigating the Existing Video Learning Project With NeocortexAPI:

## Workflow of the VideoLearning Project:

The overall project can be found in the [Project Folder](https://github.com/ddobric/neocortexapi/tree/SequenceLearning_ToanTruong/Project12_HTMCLAVideoLearning/HTMVideoLearning). This project contemplates the existing Sequence Learning procedure in [SequenceLearning.cs](https://github.com/ddobric/neocortexapi/tree/master/source/Samples/NeoCortexApiSample). WIth the help of python libraries the input training sets have been generated. [DataGeneration](https://github.com/ddobric/neocortexapi/tree/SequenceLearning_ToanTruong/DataGeneration). Three videos have been created with moving circle, triangle and rectangle. The program tries to read videos as input and for that a library has been created using OpenCV2. To run the project in the C# platform this [VideoLibrary](https://github.com/ddobric/neocortexapi/tree/SequenceLearning_ToanTruong/Project12_HTMCLAVideoLearning/HTMVideoLearning/VideoLibrary) needed some nuget packages named [Emgu.CV](https://www.nuget.org/packages/Emgu.CV/), [Emgu.CV.Bitmap](https://www.nuget.org/packages/Emgu.CV.Bitmap/) and [Emgu.CV.runtimes.windows](https://www.nuget.org/packages/Emgu.CV.runtime.windows/) with version higher than 4.5.3. The project reads input videos defined in the path and convert each videos into sequence of bit arrays. These bit arrays then pushed to the Spatial pooler where the learning stage begins. Homeostatic Plasticity Controller is connected with the SP so that it can reach to the stable state without forgetting. Afterwards the Temporal memory is introduced and the learning procedure is continued with SP and TM. The testing section has also been added where prediction is done from an input frame and the corresponding video has been generated depending on the correct prediction.

Current encoding mechanism of the frames allows the conversion of each pixels into a portion in input bit array which is then pushed to the HTM model for training purpose. There are three sets of video in the VideoLibrary/SmallTrainingSet which are all in black and white(Circle, Triangle and Rectangle). These are all small size videos containing one label for each video. For testing and experimental purpose we have created another three small videos which contains label named Pentagon, Star and Hexagon accordingly. These newly created data sets are all in black and white color mode. Currently, we are trying to analyse accuracy of the model when it is being tested with these newly created data sets after training. Now we are creating videos with PURE color mode. Afterwards we will start training the existing model with BINARIZEDRGB and PURE color mode videos.
